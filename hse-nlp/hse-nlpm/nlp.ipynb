{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(categories=['rec.autos','rec.motorcycles', 'sci.crypt', \n",
    "                                      'sci.electronics','sci.med','sci.space','talk.politics.guns',\n",
    "                                      'talk.politics.mideast','talk.religion.misc'])\n",
    "reg = re.compile(r'[0-9]+')\n",
    "data.data = [reg.sub(\"\", i) for i in data.data]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), max_df=0.3, min_df=10)\n",
    "vectorized_data = vectorizer.fit_transform(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=20, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LatentDirichletAllocation(n_components=20)\n",
    "model.fit(vectorized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylda = pyLDAvis.sklearn.prepare(model, vectorized_data, vectorizer, mds='mmds')\n",
    "#pylda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_data, data.target, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92        68\n",
      "           1       0.93      0.93      0.93        60\n",
      "           2       0.98      0.94      0.96        53\n",
      "           3       0.91      1.00      0.95        50\n",
      "           4       0.94      0.98      0.96        62\n",
      "           5       0.97      0.96      0.97        74\n",
      "           6       0.93      0.95      0.94        40\n",
      "           7       0.97      0.93      0.95        61\n",
      "           8       1.00      0.97      0.99        38\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       506\n",
      "   macro avg       0.95      0.95      0.95       506\n",
      "weighted avg       0.95      0.95      0.95       506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = np.argsort(model.coef_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse = {j:i for i, j in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS: rec.autos\n",
      "TOP 10:\n",
      "\n",
      "bike\n",
      "car\n",
      "cars\n",
      "toyota\n",
      "auto\n",
      "warning\n",
      "automotive\n",
      "dealer\n",
      "ford\n",
      "eliot\n",
      "\n",
      "CLASS: rec.motorcycles\n",
      "TOP 10:\n",
      "\n",
      "car\n",
      "dod\n",
      "bike\n",
      "bikes\n",
      "motorcycle\n",
      "ride\n",
      "motorcycles\n",
      "riding\n",
      "sale\n",
      "bmw\n",
      "\n",
      "CLASS: sci.crypt\n",
      "TOP 10:\n",
      "\n",
      "gun\n",
      "clipper\n",
      "encryption\n",
      "key\n",
      "code\n",
      "tapped\n",
      "crypto\n",
      "nsa\n",
      "pgp\n",
      "gtoal\n",
      "\n",
      "CLASS: sci.electronics\n",
      "TOP 10:\n",
      "\n",
      "space\n",
      "circuit\n",
      "motorola\n",
      "power\n",
      "electronics\n",
      "mhz\n",
      "ee\n",
      "tv\n",
      "usl\n",
      "grace\n",
      "\n",
      "CLASS: sci.med\n",
      "TOP 10:\n",
      "\n",
      "space\n",
      "doctor\n",
      "cancer\n",
      "pitt\n",
      "medical\n",
      "disease\n",
      "msg\n",
      "treatment\n",
      "vaked\n",
      "information\n",
      "\n",
      "CLASS: sci.space\n",
      "TOP 10:\n",
      "\n",
      "car\n",
      "space\n",
      "orbit\n",
      "moon\n",
      "dc\n",
      "launch\n",
      "planets\n",
      "earth\n",
      "rockets\n",
      "sunset\n",
      "\n",
      "CLASS: talk.politics.guns\n",
      "TOP 10:\n",
      "\n",
      "space\n",
      "gun\n",
      "guns\n",
      "waco\n",
      "firearms\n",
      "atf\n",
      "weapons\n",
      "batf\n",
      "ranch\n",
      "cnn\n",
      "\n",
      "CLASS: talk.politics.mideast\n",
      "TOP 10:\n",
      "\n",
      "distribution\n",
      "israeli\n",
      "israel\n",
      "serdar\n",
      "turkish\n",
      "argic\n",
      "jewish\n",
      "jews\n",
      "iran\n",
      "angmar\n",
      "\n",
      "CLASS: talk.religion.misc\n",
      "TOP 10:\n",
      "\n",
      "thanks\n",
      "christian\n",
      "morality\n",
      "bible\n",
      "god\n",
      "koresh\n",
      "homosexuality\n",
      "beast\n",
      "frank\n",
      "happened\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data.target_names)):\n",
    "    print('CLASS:', data.target_names[i])\n",
    "    print('TOP 10:\\n')\n",
    "    for j in range(10):\n",
    "        print(inverse[args[i][-j]])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

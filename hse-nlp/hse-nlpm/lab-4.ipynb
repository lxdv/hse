{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В рязанской колонии заключенный ударил сотруд...</td>\n",
       "      <td>Следователи Скопинского МСО СУ СК РФ по Рязан...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>«Работа такая…» Политолог о заявлениях на Укр...</td>\n",
       "      <td>История Российской Федерации закончится распа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Роскосмос начал сбор анонимных жалоб на наруш...</td>\n",
       "      <td>МОСКВА, 28 фев — РИА Новости. Госкорпорация «...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Срочно: Возвращение культурных ценностей в КН...</td>\n",
       "      <td>Вашингтон, 28 февраля /Синьхуа/ — Возвращение...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Лекция о кондитерской династии Абрикосовых пр...</td>\n",
       "      <td>МОСКВА, 28 февраля. /ТАСС/. Лекцию о знаменит...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   В рязанской колонии заключенный ударил сотруд...   \n",
       "1   «Работа такая…» Политолог о заявлениях на Укр...   \n",
       "2   Роскосмос начал сбор анонимных жалоб на наруш...   \n",
       "3   Срочно: Возвращение культурных ценностей в КН...   \n",
       "4   Лекция о кондитерской династии Абрикосовых пр...   \n",
       "\n",
       "                                               descr  \n",
       "0   Следователи Скопинского МСО СУ СК РФ по Рязан...  \n",
       "1   История Российской Федерации закончится распа...  \n",
       "2   МОСКВА, 28 фев — РИА Новости. Госкорпорация «...  \n",
       "3   Вашингтон, 28 февраля /Синьхуа/ — Возвращение...  \n",
       "4   МОСКВА, 28 февраля. /ТАСС/. Лекцию о знаменит...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "\n",
    "# data - first 100k from https://drive.google.com/file/d/1c5-PBIwxmzudrR5JUJv_Q_-hq2Ea2CMh/edit\n",
    "\n",
    "data = pd.read_json('rambler-news/100k.json', lines=True)[['title', 'descr']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize data\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    min_df = 10, \n",
    "    max_df = 0.3,\n",
    "    max_features=20000,\n",
    "    stop_words=stopwords.words('russian'),\n",
    "    token_pattern=r'[А-Я-а-яA-Za-z]+')\n",
    "\n",
    "vectorizer.fit(np.concatenate([data['title'], data['descr']]))\n",
    "vocab = {j:i for i, j in vectorizer.vocabulary_.items()}\n",
    "\n",
    "titles = vectorizer.transform(data['title'])\n",
    "descrs = vectorizer.transform(data['descr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descr</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>descr_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В рязанской колонии заключенный ударил сотруд...</td>\n",
       "      <td>Следователи Скопинского МСО СУ СК РФ по Рязан...</td>\n",
       "      <td>[3116, 4786, 6478, 7346, 15158, 16513, 18149]</td>\n",
       "      <td>[13, 967, 1104, 1621, 3092, 3093, 3116, 3610, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>«Работа такая…» Политолог о заявлениях на Укр...</td>\n",
       "      <td>История Российской Федерации закончится распа...</td>\n",
       "      <td>[12017, 14184, 15009, 17350, 18247]</td>\n",
       "      <td>[190, 311, 364, 418, 523, 839, 1470, 1696, 194...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Роскосмос начал сбор анонимных жалоб на наруш...</td>\n",
       "      <td>МОСКВА, 28 фев — РИА Новости. Госкорпорация «...</td>\n",
       "      <td>[757, 4428, 8697, 8852, 13768, 14996, 15284, 1...</td>\n",
       "      <td>[0, 262, 326, 434, 757, 779, 1236, 1237, 1349,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Срочно: Возвращение культурных ценностей в КН...</td>\n",
       "      <td>Вашингтон, 28 февраля /Синьхуа/ — Возвращение...</td>\n",
       "      <td>[2121, 6416, 7095, 14745, 16524, 16787, 16833,...</td>\n",
       "      <td>[1571, 2121, 2793, 5158, 6416, 7095, 7262, 733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Лекция о кондитерской династии Абрикосовых пр...</td>\n",
       "      <td>МОСКВА, 28 февраля. /ТАСС/. Лекцию о знаменит...</td>\n",
       "      <td>[1608, 3840, 7226, 7625, 13805]</td>\n",
       "      <td>[8, 396, 867, 1608, 1640, 3085, 3171, 3242, 35...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   В рязанской колонии заключенный ударил сотруд...   \n",
       "1   «Работа такая…» Политолог о заявлениях на Укр...   \n",
       "2   Роскосмос начал сбор анонимных жалоб на наруш...   \n",
       "3   Срочно: Возвращение культурных ценностей в КН...   \n",
       "4   Лекция о кондитерской династии Абрикосовых пр...   \n",
       "\n",
       "                                               descr  \\\n",
       "0   Следователи Скопинского МСО СУ СК РФ по Рязан...   \n",
       "1   История Российской Федерации закончится распа...   \n",
       "2   МОСКВА, 28 фев — РИА Новости. Госкорпорация «...   \n",
       "3   Вашингтон, 28 февраля /Синьхуа/ — Возвращение...   \n",
       "4   МОСКВА, 28 февраля. /ТАСС/. Лекцию о знаменит...   \n",
       "\n",
       "                                        title_tokens  \\\n",
       "0      [3116, 4786, 6478, 7346, 15158, 16513, 18149]   \n",
       "1                [12017, 14184, 15009, 17350, 18247]   \n",
       "2  [757, 4428, 8697, 8852, 13768, 14996, 15284, 1...   \n",
       "3  [2121, 6416, 7095, 14745, 16524, 16787, 16833,...   \n",
       "4                    [1608, 3840, 7226, 7625, 13805]   \n",
       "\n",
       "                                        descr_tokens  \n",
       "0  [13, 967, 1104, 1621, 3092, 3093, 3116, 3610, ...  \n",
       "1  [190, 311, 364, 418, 523, 839, 1470, 1696, 194...  \n",
       "2  [0, 262, 326, 434, 757, 779, 1236, 1237, 1349,...  \n",
       "3  [1571, 2121, 2793, 5158, 6416, 7095, 7262, 733...  \n",
       "4  [8, 396, 867, 1608, 1640, 3085, 3171, 3242, 35...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title_tokens'] = [i.indices for i in titles]\n",
    "data['descr_tokens'] = [i.indices for i in descrs]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['title_tokens'].map(lambda x: len(x)) != 0]\n",
    "data = data[data['descr_tokens'].map(lambda x: len(x)) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "n_iters = 1000\n",
    "batch_size = 1\n",
    "lr = 0.01\n",
    "total_loss = 0\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random word embeddings\n",
    "w = np.random.normal(1e-6, 1e-7, size=(len(vocab), embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update weights\n",
    "def update(w, vt, tokens):\n",
    "    for token in tokens:\n",
    "        w[token] -= vt\n",
    "    return w\n",
    "\n",
    "def loss(u, v, vv):\n",
    "    # customized warp because X/N-1 is always const due to fact we sample data\n",
    "    norm_uv = np.linalg.norm(u) * np.linalg.norm(v)\n",
    "    norm_uvv = np.linalg.norm(u) * np.linalg.norm(vv)\n",
    "    \n",
    "    return np.dot(u,v) / norm_uv - np.dot(u,vv) / norm_uvv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1000 iterations. Loss - 0.09474564252739137]\n",
      "[100/1000 iterations. Loss - 0.15903216390828015]\n",
      "[200/1000 iterations. Loss - 0.07207707129356045]\n",
      "[300/1000 iterations. Loss - 0.2529516124329169]\n",
      "[400/1000 iterations. Loss - 0.016311463557099504]\n",
      "[500/1000 iterations. Loss - 0.16602353451279708]\n",
      "[600/1000 iterations. Loss - 0.09080578263395689]\n",
      "[700/1000 iterations. Loss - 0.1831070733380612]\n",
      "[800/1000 iterations. Loss - 0.12292492872727212]\n",
      "[900/1000 iterations. Loss - 0.18948962969800492]\n"
     ]
    }
   ],
   "source": [
    "gr_title = np.zeros(embedding_size)\n",
    "gr_descr = np.zeros(embedding_size)\n",
    "gr_neg = np.zeros(embedding_size)\n",
    "\n",
    "for i in range(0, n_iters):\n",
    "    for j in range(batch_size):\n",
    "        sample = data.sample(n=2).values\n",
    "        title = sample[0,2]\n",
    "        descr = sample[0,3]\n",
    "        neg = sample[1,3]\n",
    "        \n",
    "        # aggr\n",
    "        title_w = np.max(w[title], axis=0)\n",
    "        descr_w = np.max(w[descr], axis=0)\n",
    "        neg_w = np.max(w[neg], axis=0)\n",
    "\n",
    "        total_loss += loss(title_w, descr_w, neg_w)\n",
    "\n",
    "        gr_title = gr_title + lr * (neg_w - descr_w)\n",
    "        gr_descr = gr_descr - lr * title_w\n",
    "        gr_neg = gr_neg + lr * title_w\n",
    "\n",
    "        if (j + 1) % batch_size == 0:\n",
    "            w = update(w, gr_title, title)\n",
    "            w = update(w, gr_descr, descr)\n",
    "            w = update(w, gr_neg, neg)\n",
    "            \n",
    "            # zero grad\n",
    "            gr_title = np.zeros(embedding_size)\n",
    "            gr_descr = np.zeros(embedding_size)\n",
    "            gr_neg = np.zeros(embedding_size)\n",
    "            w[w < 0] = 1e-16\n",
    "\n",
    "    if i % print_every == 0:\n",
    "        print('[{}/{} iterations. Loss - {}]'.format(i, n_iters, total_loss))\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding distances\n",
    "\n",
    "distances = euclidean_distances(w)\n",
    "np.fill_diagonal(distances, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['штатов',\n",
       " 'американский',\n",
       " 'дональд',\n",
       " 'трампа',\n",
       " 'соединенных',\n",
       " 'агентство',\n",
       " 'вашингтоне',\n",
       " 'конгресса',\n",
       " 'переговоры',\n",
       " 'военный']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "[vocab[i] for i in np.argsort(distances[vectorizer.vocabulary_['трамп']])[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['владимир',\n",
       " 'совета',\n",
       " 'стран',\n",
       " 'частности',\n",
       " 'безопасности',\n",
       " 'председатель',\n",
       " 'среди',\n",
       " 'российская',\n",
       " 'страны',\n",
       " 'ситуации']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "[vocab[i] for i in np.argsort(distances[vectorizer.vocabulary_['путин']])[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['москва',\n",
       " 'мид',\n",
       " 'будут',\n",
       " 'российского',\n",
       " 'подчеркнул',\n",
       " 'тасс',\n",
       " 'глава',\n",
       " 'числе',\n",
       " 'риа',\n",
       " 'федерации']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "[vocab[i] for i in np.argsort(distances[vectorizer.vocabulary_['новости']])[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['украинских',\n",
       " 'петр',\n",
       " 'киеве',\n",
       " 'украиной',\n",
       " 'провокации',\n",
       " 'экономика',\n",
       " 'президентских',\n",
       " 'марта',\n",
       " 'заявила',\n",
       " 'ответ']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "[vocab[i] for i in np.argsort(distances[vectorizer.vocabulary_['украина']])[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['отношения',\n",
       " 'отношений',\n",
       " 'слова',\n",
       " 'европы',\n",
       " 'дипломат',\n",
       " 'сфере',\n",
       " 'законопроект',\n",
       " 'договора',\n",
       " 'национальной',\n",
       " 'председателя']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "[vocab[i] for i in np.argsort(distances[vectorizer.vocabulary_['лавров']])[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['западная',\n",
       " 'протестующие',\n",
       " 'питьевой',\n",
       " 'семеро',\n",
       " 'сайтах',\n",
       " 'мюллера',\n",
       " 'марио',\n",
       " 'густой',\n",
       " 'нигерии',\n",
       " 'животного']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "[vocab[i] for i in np.argsort(distances[vectorizer.vocabulary_['telegram']])[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['киев',\n",
       " 'украине',\n",
       " 'властей',\n",
       " 'киева',\n",
       " 'требования',\n",
       " 'считает',\n",
       " 'сообщило',\n",
       " 'лишь',\n",
       " 'республики',\n",
       " 'добавил']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "[vocab[i] for i in np.argsort(distances[vectorizer.vocabulary_['порошенко']])[:10]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

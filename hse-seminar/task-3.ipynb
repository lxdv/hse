{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-3\n",
    "## Cat / Dog classifier using transfer learning technique\n",
    "### 1. Use ConvNet as feature extractor\n",
    "### 2. Fine-tune ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.mobilenet import MobileNetV2\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet as feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build train / test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataset_train = datasets.ImageFolder('./data/small/train/', transform=transform)\n",
    "dataset_val = datasets.ImageFolder('./data/small/validation/', transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load MobileNetV2 (with no last layer) and pretrained on ResNet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MobileNetV2().cuda()\n",
    "model.load_state_dict(torch.load('utils/mobilenet_v2.pth.tar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train / Val inference to extract features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "with torch.no_grad():\n",
    "    for data, target in train_loader:\n",
    "        X_train.extend(model(data.cuda()).cpu().numpy())\n",
    "        y_train.extend(target.numpy())\n",
    "        \n",
    "    for data, target in val_loader:\n",
    "        X_test.extend(model(data.cuda()).cpu().numpy())\n",
    "        y_test.extend(target.numpy())\n",
    "\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.vstack(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use different ML methods for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.74      0.86      0.80       128\n",
      "        dogs       0.83      0.70      0.76       128\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       256\n",
      "   macro avg       0.79      0.78      0.78       256\n",
      "weighted avg       0.79      0.78      0.78       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.61      0.80      0.69       128\n",
      "        dogs       0.71      0.48      0.58       128\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       256\n",
      "   macro avg       0.66      0.64      0.64       256\n",
      "weighted avg       0.66      0.64      0.64       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(gamma='auto').fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.63      0.60      0.62       128\n",
      "        dogs       0.62      0.65      0.63       128\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       256\n",
      "   macro avg       0.63      0.62      0.62       256\n",
      "weighted avg       0.63      0.62      0.62       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.76      0.74      0.75       128\n",
      "        dogs       0.75      0.77      0.76       128\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       256\n",
      "   macro avg       0.75      0.75      0.75       256\n",
      "weighted avg       0.75      0.75      0.75       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500).fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.68      0.72      0.70       128\n",
      "        dogs       0.70      0.66      0.68       128\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       256\n",
      "   macro avg       0.69      0.69      0.69       256\n",
      "weighted avg       0.69      0.69      0.69       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.87      0.87      0.87       128\n",
      "        dogs       0.87      0.88      0.87       128\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       256\n",
      "   macro avg       0.87      0.87      0.87       256\n",
      "weighted avg       0.87      0.87      0.87       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add classification layer to MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2_CatDog(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(MobileNetV2_CatDog, self).__init__()\n",
    "        self.model = model\n",
    "        self.linear = nn.Linear(model.classifier[1].in_features, 2)\n",
    "        \n",
    "    def forward(self, x, extract=False):\n",
    "        x = self.model(x)\n",
    "        if extract:\n",
    "            return x\n",
    "        x = F.softmax(self.linear(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train / val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx + 1) % len(train_loader) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx , len(train_loader),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('Test set: Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Define MobileNetV2 for Cat / Dog classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2().cuda()\n",
    "model.load_state_dict(torch.load('utils/mobilenet_v2.pth.tar'))\n",
    "\n",
    "model = MobileNetV2_CatDog(model).cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train new network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [7/8 (88%)]\tLoss: 0.752505\n",
      "Test set: Accuracy: 170/256 (66.41%)\n",
      "\n",
      "Train Epoch: 2 [7/8 (88%)]\tLoss: 0.713997\n",
      "Test set: Accuracy: 174/256 (67.97%)\n",
      "\n",
      "Train Epoch: 3 [7/8 (88%)]\tLoss: 0.710280\n",
      "Test set: Accuracy: 179/256 (69.92%)\n",
      "\n",
      "Train Epoch: 4 [7/8 (88%)]\tLoss: 0.716692\n",
      "Test set: Accuracy: 180/256 (70.31%)\n",
      "\n",
      "Train Epoch: 5 [7/8 (88%)]\tLoss: 0.700664\n",
      "Test set: Accuracy: 184/256 (71.88%)\n",
      "\n",
      "Train Epoch: 6 [7/8 (88%)]\tLoss: 0.715826\n",
      "Test set: Accuracy: 183/256 (71.48%)\n",
      "\n",
      "Train Epoch: 7 [7/8 (88%)]\tLoss: 0.687677\n",
      "Test set: Accuracy: 183/256 (71.48%)\n",
      "\n",
      "Train Epoch: 8 [7/8 (88%)]\tLoss: 0.706599\n",
      "Test set: Accuracy: 185/256 (72.27%)\n",
      "\n",
      "Train Epoch: 9 [7/8 (88%)]\tLoss: 0.708344\n",
      "Test set: Accuracy: 186/256 (72.66%)\n",
      "\n",
      "Train Epoch: 10 [7/8 (88%)]\tLoss: 0.703584\n",
      "Test set: Accuracy: 186/256 (72.66%)\n",
      "\n",
      "Train Epoch: 11 [7/8 (88%)]\tLoss: 0.692964\n",
      "Test set: Accuracy: 188/256 (73.44%)\n",
      "\n",
      "Train Epoch: 12 [7/8 (88%)]\tLoss: 0.697720\n",
      "Test set: Accuracy: 188/256 (73.44%)\n",
      "\n",
      "Train Epoch: 13 [7/8 (88%)]\tLoss: 0.701560\n",
      "Test set: Accuracy: 188/256 (73.44%)\n",
      "\n",
      "Train Epoch: 14 [7/8 (88%)]\tLoss: 0.662369\n",
      "Test set: Accuracy: 191/256 (74.61%)\n",
      "\n",
      "Train Epoch: 15 [7/8 (88%)]\tLoss: 0.671755\n",
      "Test set: Accuracy: 189/256 (73.83%)\n",
      "\n",
      "Train Epoch: 16 [7/8 (88%)]\tLoss: 0.693947\n",
      "Test set: Accuracy: 189/256 (73.83%)\n",
      "\n",
      "Train Epoch: 17 [7/8 (88%)]\tLoss: 0.663294\n",
      "Test set: Accuracy: 190/256 (74.22%)\n",
      "\n",
      "Train Epoch: 18 [7/8 (88%)]\tLoss: 0.684341\n",
      "Test set: Accuracy: 190/256 (74.22%)\n",
      "\n",
      "Train Epoch: 19 [7/8 (88%)]\tLoss: 0.678634\n",
      "Test set: Accuracy: 191/256 (74.61%)\n",
      "\n",
      "Train Epoch: 20 [7/8 (88%)]\tLoss: 0.671265\n",
      "Test set: Accuracy: 192/256 (75.00%)\n",
      "\n",
      "Train Epoch: 21 [7/8 (88%)]\tLoss: 0.665109\n",
      "Test set: Accuracy: 192/256 (75.00%)\n",
      "\n",
      "Train Epoch: 22 [7/8 (88%)]\tLoss: 0.680111\n",
      "Test set: Accuracy: 193/256 (75.39%)\n",
      "\n",
      "Train Epoch: 23 [7/8 (88%)]\tLoss: 0.649629\n",
      "Test set: Accuracy: 195/256 (76.17%)\n",
      "\n",
      "Train Epoch: 24 [7/8 (88%)]\tLoss: 0.675371\n",
      "Test set: Accuracy: 194/256 (75.78%)\n",
      "\n",
      "Train Epoch: 25 [7/8 (88%)]\tLoss: 0.669299\n",
      "Test set: Accuracy: 196/256 (76.56%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 26):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Extract features for ML methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "with torch.no_grad():\n",
    "    for data, target in train_loader:\n",
    "        X_train.extend(model(data.cuda(), extract=True).cpu().numpy())\n",
    "        y_train.extend(target.numpy())\n",
    "        \n",
    "    for data, target in val_loader:\n",
    "        X_test.extend(model(data.cuda(), extract=True).cpu().numpy())\n",
    "        y_test.extend(target.numpy())\n",
    "\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.vstack(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.98      0.98      0.98       128\n",
      "        dogs       0.98      0.98      0.98       128\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       256\n",
      "   macro avg       0.98      0.98      0.98       256\n",
      "weighted avg       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       1.00      0.66      0.80       128\n",
      "        dogs       0.75      1.00      0.86       128\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       256\n",
      "   macro avg       0.87      0.83      0.83       256\n",
      "weighted avg       0.87      0.83      0.83       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(gamma='auto').fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.93      0.95      0.94       128\n",
      "        dogs       0.95      0.93      0.94       128\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       256\n",
      "   macro avg       0.94      0.94      0.94       256\n",
      "weighted avg       0.94      0.94      0.94       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.98      0.96      0.97       128\n",
      "        dogs       0.96      0.98      0.97       128\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       256\n",
      "   macro avg       0.97      0.97      0.97       256\n",
      "weighted avg       0.97      0.97      0.97       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=2500).fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.98      0.95      0.96       128\n",
      "        dogs       0.95      0.98      0.97       128\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       256\n",
      "   macro avg       0.97      0.96      0.96       256\n",
      "weighted avg       0.97      0.96      0.96       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.96      0.98      0.97       128\n",
      "        dogs       0.98      0.96      0.97       128\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       256\n",
      "   macro avg       0.97      0.97      0.97       256\n",
      "weighted avg       0.97      0.97      0.97       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test), target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1-score\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/17x7mJ764ID8LCqPst4XrE0PfI7VYJtKBtAJnYxIBveE/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  method | feature extractor | fune-tune |\n",
    "| --- | --- | --- |\n",
    "|  KNN | 0,78 | **0,98** |\n",
    "|  SVM | 0,64 | 0,83 |\n",
    "|  Decision Tree | 0,62 | 0,94 |\n",
    "|  Random Forest | 0,75 | 0,97 |\n",
    "|  Gradient Boosting | 0,69 | 0,96 |\n",
    "|  MLP | **0,87** | 0,97 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

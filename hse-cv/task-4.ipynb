{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graph initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands_train_dir='data/speech_data/commands/train/'\n",
    "commands_test_dir='data/speech_data/commands/test/'\n",
    "\n",
    "digits_train_dir='data/speech_data/digits/test/'\n",
    "digits_test_dir='data/speech_data/digits/train/'\n",
    "\n",
    "\n",
    "def load_graph(filename,name=''):\n",
    "    \"\"\"Unpersists graph from file as default graph.\"\"\"\n",
    "    with tf.gfile.FastGFile(filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name=name)\n",
    "    return graph_def\n",
    "\n",
    "def run_graph(sess,output_tensor,wav_file):\n",
    "    with open(wav_file, 'rb') as wav_file:\n",
    "        wav_data = wav_file.read()\n",
    "    input_layer_name = 'wav_data:0'\n",
    "    predictions, = sess.run(output_tensor, {input_layer_name: wav_data})\n",
    "    return predictions        \n",
    "\n",
    "def is_wav(path):\n",
    "    _, file_extension = os.path.splitext(path)\n",
    "    return file_extension.lower() in ['.wav']\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph_def=load_graph('data/speech_data/conv_actions_frozen.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create train / val for commands by extracting features from NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty((0, 64000))\n",
    "X_test = np.empty((0, 64000))\n",
    "\n",
    "y_train = np.empty(0)\n",
    "y_test = np.empty(0)\n",
    "\n",
    "command_labels=['_silence_','_unknown_','yes','no','up','down','left','right','on','off','stop','go']\n",
    "with tf.Session() as sess:\n",
    "    out_tensor = sess.graph.get_tensor_by_name('Reshape_1:0')\n",
    "    for d in next(os.walk(commands_test_dir))[1]:\n",
    "        for f in next(os.walk(os.path.join(commands_test_dir,d)))[2]:\n",
    "            if is_wav(f):\n",
    "                wav_file=os.path.join(commands_test_dir,d,f)        \n",
    "                preds=run_graph(sess,out_tensor,wav_file)\n",
    "                X_test = np.vstack([X_test, np.array(preds)])\n",
    "                y_test = np.append(y_test, command_labels.index(d))\n",
    "    for d in next(os.walk(commands_train_dir))[1]:\n",
    "        for f in next(os.walk(os.path.join(commands_train_dir,d)))[2]:\n",
    "            if is_wav(f):\n",
    "                wav_file=os.path.join(commands_train_dir,d,f)        \n",
    "                preds=run_graph(sess,out_tensor,wav_file)\n",
    "                X_train = np.vstack([X_train, np.array(preds)])\n",
    "                y_train = np.append(y_train, command_labels.index(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use different ML methods for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.77      1.00      0.87        10\n",
      "         3.0       0.83      0.50      0.62        10\n",
      "         4.0       0.17      0.10      0.12        10\n",
      "         5.0       0.55      0.60      0.57        10\n",
      "         6.0       0.58      0.70      0.64        10\n",
      "         7.0       1.00      0.50      0.67        10\n",
      "         8.0       0.75      0.60      0.67        10\n",
      "         9.0       0.60      0.30      0.40        10\n",
      "        10.0       0.38      1.00      0.55         8\n",
      "        11.0       0.91      1.00      0.95        10\n",
      "\n",
      "   micro avg       0.62      0.62      0.62        98\n",
      "   macro avg       0.65      0.63      0.61        98\n",
      "weighted avg       0.66      0.62      0.61        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.40      1.00      0.57        10\n",
      "         3.0       1.00      0.50      0.67        10\n",
      "         4.0       0.20      0.10      0.13        10\n",
      "         5.0       0.00      0.00      0.00        10\n",
      "         6.0       0.23      0.70      0.34        10\n",
      "         7.0       0.26      0.60      0.36        10\n",
      "         8.0       1.00      0.20      0.33        10\n",
      "         9.0       0.00      0.00      0.00        10\n",
      "        10.0       0.71      0.62      0.67         8\n",
      "        11.0       0.00      0.00      0.00        10\n",
      "\n",
      "   micro avg       0.37      0.37      0.37        98\n",
      "   macro avg       0.38      0.37      0.31        98\n",
      "weighted avg       0.37      0.37      0.30        98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xperience/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = SVC(gamma='auto').fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00        10\n",
      "         3.0       0.14      0.40      0.21        10\n",
      "         4.0       0.50      0.20      0.29        10\n",
      "         5.0       0.11      0.10      0.11        10\n",
      "         6.0       0.50      0.30      0.37        10\n",
      "         7.0       0.27      0.30      0.29        10\n",
      "         8.0       0.22      0.20      0.21        10\n",
      "         9.0       0.06      0.10      0.08        10\n",
      "        10.0       0.29      0.25      0.27         8\n",
      "        11.0       0.33      0.10      0.15        10\n",
      "\n",
      "   micro avg       0.19      0.19      0.19        98\n",
      "   macro avg       0.24      0.20      0.20        98\n",
      "weighted avg       0.24      0.19      0.20        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.62      0.80      0.70        10\n",
      "         3.0       0.88      0.70      0.78        10\n",
      "         4.0       1.00      0.10      0.18        10\n",
      "         5.0       0.83      0.50      0.62        10\n",
      "         6.0       0.62      0.80      0.70        10\n",
      "         7.0       1.00      0.70      0.82        10\n",
      "         8.0       0.67      0.40      0.50        10\n",
      "         9.0       0.62      0.80      0.70        10\n",
      "        10.0       0.33      0.75      0.46         8\n",
      "        11.0       0.77      1.00      0.87        10\n",
      "\n",
      "   micro avg       0.65      0.65      0.65        98\n",
      "   macro avg       0.73      0.66      0.63        98\n",
      "weighted avg       0.74      0.65      0.64        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500).fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.67      0.80      0.73        10\n",
      "         3.0       0.60      0.30      0.40        10\n",
      "         4.0       0.00      0.00      0.00        10\n",
      "         5.0       0.17      0.20      0.18        10\n",
      "         6.0       0.67      0.40      0.50        10\n",
      "         7.0       0.55      0.60      0.57        10\n",
      "         8.0       0.08      0.10      0.09        10\n",
      "         9.0       0.27      0.30      0.29        10\n",
      "        10.0       0.38      0.38      0.38         8\n",
      "        11.0       0.29      0.50      0.37        10\n",
      "\n",
      "   micro avg       0.36      0.36      0.36        98\n",
      "   macro avg       0.37      0.36      0.35        98\n",
      "weighted avg       0.37      0.36      0.35        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.91      1.00      0.95        10\n",
      "         3.0       0.90      0.90      0.90        10\n",
      "         4.0       0.67      0.20      0.31        10\n",
      "         5.0       0.73      0.80      0.76        10\n",
      "         6.0       0.90      0.90      0.90        10\n",
      "         7.0       1.00      0.70      0.82        10\n",
      "         8.0       0.88      0.70      0.78        10\n",
      "         9.0       0.75      0.90      0.82        10\n",
      "        10.0       0.47      1.00      0.64         8\n",
      "        11.0       1.00      0.90      0.95        10\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        98\n",
      "   macro avg       0.82      0.80      0.78        98\n",
      "weighted avg       0.83      0.80      0.79        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create train / val for digits by extracting features from NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.empty((0, 64000))\n",
    "X_test = np.empty((0, 64000))\n",
    "\n",
    "y_train = np.empty(0)\n",
    "y_test = np.empty(0)\n",
    "\n",
    "digits_labels=['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "with tf.Session() as sess:\n",
    "    out_tensor = sess.graph.get_tensor_by_name('Reshape_1:0')\n",
    "    for d in next(os.walk(digits_test_dir))[1]:\n",
    "        for f in next(os.walk(os.path.join(digits_test_dir,d)))[2]:\n",
    "            if is_wav(f):\n",
    "                wav_file=os.path.join(digits_test_dir,d,f)        \n",
    "                preds=run_graph(sess,out_tensor,wav_file)\n",
    "                X_test = np.vstack([X_test, np.array(preds)])\n",
    "                y_test = np.append(y_test, digits_labels.index(d))\n",
    "    for d in next(os.walk(digits_train_dir))[1]:\n",
    "        for f in next(os.walk(os.path.join(digits_train_dir,d)))[2]:\n",
    "            if is_wav(f):\n",
    "                wav_file=os.path.join(digits_train_dir,d,f)        \n",
    "                preds=run_graph(sess,out_tensor,wav_file)\n",
    "                X_train = np.vstack([X_train, np.array(preds)])\n",
    "                y_train = np.append(y_train, digits_labels.index(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use different ML methods for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       0.62      0.71      0.67         7\n",
      "         2.0       0.86      0.86      0.86         7\n",
      "         3.0       0.88      1.00      0.93         7\n",
      "         4.0       0.75      0.86      0.80         7\n",
      "         5.0       1.00      0.71      0.83         7\n",
      "         6.0       0.75      0.60      0.67         5\n",
      "         7.0       0.60      0.60      0.60         5\n",
      "         8.0       0.78      1.00      0.88         7\n",
      "         9.0       1.00      0.71      0.83         7\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        65\n",
      "   macro avg       0.82      0.81      0.81        65\n",
      "weighted avg       0.83      0.82      0.81        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       0.86      0.86      0.86         7\n",
      "         2.0       0.39      1.00      0.56         7\n",
      "         3.0       0.70      1.00      0.82         7\n",
      "         4.0       0.83      0.71      0.77         7\n",
      "         5.0       0.83      0.71      0.77         7\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.00      0.00      0.00         5\n",
      "         8.0       0.64      1.00      0.78         7\n",
      "         9.0       0.71      0.71      0.71         7\n",
      "\n",
      "   micro avg       0.65      0.65      0.65        65\n",
      "   macro avg       0.50      0.60      0.53        65\n",
      "weighted avg       0.53      0.65      0.57        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xperience/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = SVC(gamma='auto').fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.50      0.43         6\n",
      "         1.0       1.00      0.57      0.73         7\n",
      "         2.0       0.25      0.14      0.18         7\n",
      "         3.0       0.56      0.71      0.63         7\n",
      "         4.0       0.56      0.71      0.63         7\n",
      "         5.0       0.44      0.57      0.50         7\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.25      0.20      0.22         5\n",
      "         8.0       0.83      0.71      0.77         7\n",
      "         9.0       0.56      0.71      0.63         7\n",
      "\n",
      "   micro avg       0.51      0.51      0.51        65\n",
      "   macro avg       0.48      0.48      0.47        65\n",
      "weighted avg       0.51      0.51      0.49        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      0.71      0.83         7\n",
      "         2.0       0.58      1.00      0.74         7\n",
      "         3.0       0.75      0.86      0.80         7\n",
      "         4.0       0.75      0.86      0.80         7\n",
      "         5.0       1.00      0.86      0.92         7\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.83      1.00      0.91         5\n",
      "         8.0       1.00      1.00      1.00         7\n",
      "         9.0       0.86      0.86      0.86         7\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        65\n",
      "   macro avg       0.78      0.81      0.79        65\n",
      "weighted avg       0.80      0.83      0.80        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xperience/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500).fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.67      0.73         6\n",
      "         1.0       0.50      0.43      0.46         7\n",
      "         2.0       0.50      0.57      0.53         7\n",
      "         3.0       0.44      0.57      0.50         7\n",
      "         4.0       0.42      0.71      0.53         7\n",
      "         5.0       0.67      0.57      0.62         7\n",
      "         6.0       0.50      0.20      0.29         5\n",
      "         7.0       0.67      0.40      0.50         5\n",
      "         8.0       0.80      0.57      0.67         7\n",
      "         9.0       0.67      0.86      0.75         7\n",
      "\n",
      "   micro avg       0.57      0.57      0.57        65\n",
      "   macro avg       0.60      0.56      0.56        65\n",
      "weighted avg       0.59      0.57      0.56        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       0.75      0.86      0.80         7\n",
      "         2.0       0.50      0.86      0.63         7\n",
      "         3.0       1.00      0.86      0.92         7\n",
      "         4.0       0.70      1.00      0.82         7\n",
      "         5.0       1.00      0.71      0.83         7\n",
      "         6.0       0.00      0.00      0.00         5\n",
      "         7.0       0.83      1.00      0.91         5\n",
      "         8.0       1.00      0.71      0.83         7\n",
      "         9.0       1.00      1.00      1.00         7\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        65\n",
      "   macro avg       0.78      0.80      0.78        65\n",
      "weighted avg       0.80      0.82      0.79        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xperience/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier().fit(X_train, y_train) \n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1-score\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1QK6lDiLoPQTDUYszxRFyCQdj48kLSQQQxH4TOhn-rnI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  method | commands | digits |\n",
    "| --- | --- | --- |\n",
    "|  KNN | 0,61 | **0,81** |\n",
    "|  SVM | 0,31 | 0,53 |\n",
    "|  Decision Tree | 0,20 | 0,47 |\n",
    "|  Random Forest | 0,63 | 0,79 |\n",
    "|  Gradient Boosting | 0,35 | 0,56 |\n",
    "|  MLP | **0,78** | 0,78 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
